---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/config-map.yaml
# Source: jaeger/templates/common-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-jaeger
  labels:
    app: jaeger
    jaeger-infra: common-configmap
    chart: jaeger-0.3.5
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
data:
  cassandra.contact-points: jaeger-cassandra:9042
  cassandra.datacenter.name: "dc1"
  cassandra.keyspace: "jaeger_v1_dc1"
  cassandra.port: "9042"
  cassandra.schema.mode: "prod"
  cassandra.servers: jaeger-cassandra
  collector.host-port: jaeger-jaeger-collector:14267
  collector.http-port: "14268"
  collector.port: "14267"
  collector.zipkin.http-port: "9411"
  es.password: changeme
  es.server-urls: http://elasticsearch:9200
  es.username: elastic
  hotrod.agent-host: jaeger-jaeger-agent
  hotrod.agent-port: "6831"
  span-storage.type: "cassandra"
  query.health-check-http-port: "16687"
  query.port: "16686"
  # Not implemented
  # cassandra.archive.connections-per-host:
  # cassandra.archive.keyspace:
  # cassandra.archive.max-retry-attempts:
  # cassandra.archive.password:
  # cassandra.archive.port:
  # cassandra.archive.proto-version:
  # cassandra.archive.servers:
  # cassandra.archive.socket-keep-alive:
  # cassandra.archive.timeout:
  # cassandra.archive.username:
  # cassandra.connections-per-host:
  # cassandra.max-retry-attempts:
  # cassandra.password:
  # cassandra.proto-version:
  # cassandra.socket-keep-alive:
  # cassandra.timeout:
  # cassandra.username:
  # collector.health-check-http-port:
  # collector.num-workers:
  # collector.queue-size:
  # collector.write-cache-ttl:
  # dependency-storage.data-frequency:
  # discovery.min-peers:
  # es.archive.max-span-age:
  # es.archive.num-replicas:
  # es.archive.num-shards:
  # es.archive.password:
  # es.archive.server-urls:
  # es.archive.sniffer:
  # es.archive.username:
  # es.max-span-age:
  # es.num-replicas:
  # es.num-shards:
  # es.sniffer:
  # http-server.host-port:
  # log-level:
  # metrics-backend:
  # metrics-http-route:
  # processor.jaeger-binary.server-host-port:
  # processor.jaeger-binary.server-max-packet-size:
  # processor.jaeger-binary.server-queue-size:
  # processor.jaeger-binary.workers:
  # processor.jaeger-compact.server-host-port:
  # processor.jaeger-compact.server-max-packet-size:
  # processor.jaeger-compact.server-queue-size:
  # processor.jaeger-compact.workers:
  # processor.zipkin-compact.server-host-port:
  # processor.zipkin-compact.server-max-packet-size:
  # processor.zipkin-compact.server-queue-size:
  # processor.zipkin-compact.workers:
  # query.prefix:
  # query.static-files:
  # query.ui-config:
  query.base-path: "/jaeger"
---
# Source: hkube/templates/configmap.yaml
apiVersion: v1
data:
  versions.json: |
          {"systemVersion":"1.1.354","versions":[{"project":"api-server","tag":"v1.1.73"},{"project":"worker","tag":"v1.1.35"},{"project":"pipeline-driver","tag":"v1.1.28"},{"project":"algorunner","tag":"v1.1.5"},{"project":"simulator","tag":"v1.1.13"},{"project":"webhook-stub-ui","tag":"v1.1.2"},{"project":"algorithm-example","tag":"v1.1.7"},{"project":"deployment","tag":"v1.1.39"},{"project":"monitor-server","tag":"v1.1.18"},{"project":"algorithm-queue","tag":"v1.1.24"},{"project":"resource-manager","tag":"v1.1.32"},{"project":"task-executor","tag":"v1.1.44"},{"project":"trigger-service","tag":"v1.1.19"},{"project":"algorithm-operator","tag":"v1.1.10"},{"project": "pipeline-driver-queue","tag": "v1.1.6"},{"project":"clean-old-jobs","tag":"v1.1.2"},{"project": "cpu-load-algorithm","tag": "v1.1.3"},{"project": "storage-cleaner","tag": "v1.1.11"}]}
kind: ConfigMap
metadata:
  name: hkube-versions
  namespace: default

---
# Source: hkube/templates/configmaps/algorithm-operator-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: algorithm-operator-configmap
data: 
  NODE_ENV: production
  METRICS_PORT: "3000"

---
# Source: hkube/templates/configmaps/api-server-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-server-configmap
data:
  NODE_ENV: production
  BASE_URL_PATH: /hkube/api-server
  DEFAULT_STORAGE: s3

---
# Source: hkube/templates/configmaps/job-cleaner-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: job-cleaner-configmap
data:
  MAX_COMPLETED_JOB_AGE_HOURS: "1"

---
# Source: hkube/templates/configmaps/pipeline-driver-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pipeline-driver-configmap
data:
  NODE_ENV: production
  DEFAULT_STORAGE: s3
  METRICS_PORT: "3000"

---
# Source: hkube/templates/configmaps/pipeline-driver-queue-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pipeline-driver-queue-configmap
data:
  NODE_ENV: production
  KUBE_LOG_LEVEL: "0"
  METRICS_PORT: "3000"

---
# Source: hkube/templates/configmaps/resource-manager-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: resource-manager-configmap
data:
  NODE_ENV: production
  HKUBE_LOG_LEVEL: "0"
  INTERVAL: "2000"
  ALGORITHMS_THRESHOLD_CPU: "0.9"
  ALGORITHMS_THRESHOLD_MEM: "0.9"
  DRIVERS_THRESHOLD_CPU: "0.1"
  DRIVERS_THRESHOLD_MEM: "1"
  METRICS_PORT: "3000"
  PROMETHEUS_ENDPOINT: http://monitoring-prometheus-server.monitoring:9090/api/v1

---
# Source: hkube/templates/configmaps/results-cleaner-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: results-cleaner-configmap
data:
  OBJECT_EXPIRATION_DAYS: "90"
  DEFAULT_STORAGE: s3
  DELETE_DESTINATION: results

---
# Source: hkube/templates/configmaps/simulator-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: simulator-configmap
data:
  MONITOR_BACKEND_PATH: /hkube/monitor-server/socket.io

---
# Source: hkube/templates/configmaps/storage-cleaner-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: storage-cleaner-configmap
data:
  OBJECT_EXPIRATION_DAYS: "5"
  DEFAULT_STORAGE: s3

---
# Source: hkube/templates/configmaps/task-executor-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: task-executor-configmap
data:
  NODE_ENV: production
  METRICS_PORT: "3000"

---
# Source: hkube/templates/configmaps/trigger-service-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: trigger-service-configmap
data:
  NODE_ENV: production
  METRICS_PORT: "3000"

---
# Source: hkube/templates/configmaps/webhook-stub-ui-cm.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: webhook-stub-ui-configmap
data:
  PUBLIC_URL: "/hkube/webhook-stub-ui"

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/backup-operator-service-account.yaml

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: application-etcd-operator-etcd-backup-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-backup-operator
    heritage: Tiller
    release: application
---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/operator-service-account.yaml

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: application-etcd-operator-etcd-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-operator
    heritage: Tiller
    release: application
---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/restore-operator-service-account.yaml

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: application-etcd-operator-etcd-restore-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-restore-operator
    heritage: Tiller
    release: application
---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: application-redis-ha
  labels:
    app: "redis-ha"
    chart: redis-ha-2.1.3
    heritage: Tiller
    release: application
---
# Source: hkube/templates/algorithm-operator-role.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: algorithm-operator-serviceaccount
  labels:
    group: hkube
    app: algorithm-operator
    core: "true"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: 
  name: algorithm-operator
  labels:
    group: hkube
    app: algorithm-operator
    core: "true"
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- apiGroups: ["extensions", "apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: algorithm-operator
  namespace: 
  labels:
    group: hkube
    app: algorithm-operator
    core: "true"
subjects:
- kind: ServiceAccount
  name: algorithm-operator-serviceaccount
roleRef:
  kind: Role
  name: algorithm-operator
  apiGroup: rbac.authorization.k8s.io
---
---
# Source: hkube/templates/job-cleaner-role.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: clean-old-jobs
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: clean-old-jobs
  labels:
    group: hkube
    app: clean-old-jobs
    core: "true"
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["batch", "extensions"]
  resources: ["jobs"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: clean-old-jobs
  namespace: default
  labels:
    group: hkube
    app: clean-old-jobs
    core: "true"
subjects:
- kind: ServiceAccount
  name: clean-old-jobs
roleRef:
  kind: Role
  name: clean-old-jobs
  apiGroup: rbac.authorization.k8s.io

---
# Source: hkube/templates/resource-manager-role.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: resource-manager-serviceaccount
  labels:
    group: hkube
    app: resource-manager
    core: "true"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: resource-manager
  labels:
    group: hkube
    app: resource-manager-role
    core: "true"
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: resource-manager-clusterrole
  labels:
    group: hkube
    app: resource-manager
    core: "true"
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "watch", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: resource-manager-clusterrolebinding
  labels:
    group: hkube
    app: resource-manager
    core: "true"
subjects:
- kind: ServiceAccount
  name: resource-manager-serviceaccount
  namespace: default
roleRef:
  kind: ClusterRole
  name: resource-manager-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: resource-manager
  namespace: default
  labels:
    group: hkube
    app: resource-manager
    core: "true"
subjects:
- kind: ServiceAccount
  name: resource-manager-serviceaccount
roleRef:
  kind: Role
  name: resource-manager
  apiGroup: rbac.authorization.k8s.io
---
# Source: hkube/templates/task-executor-role.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: task-executor-serviceaccount
  labels:
    group: hkube
    app: task-executor
    core: "true"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: task-executor
  labels:
    group: hkube
    app: task-executor
    core: "true"
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- apiGroups: ["batch", "extensions"]
  resources: ["jobs"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: task-executor
  namespace: default
  labels:
    group: hkube
    app: task-executor
    core: "true"
subjects:
- kind: ServiceAccount
  name: task-executor-serviceaccount
roleRef:
  kind: Role
  name: task-executor
  apiGroup: rbac.authorization.k8s.io
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: task-executor-clusterrole
  labels:
    group: hkube
    app: task-executor
    core: "true"
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "watch", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: task-executor-clusterrolebinding
  labels:
    group: hkube
    app: task-executor
    core: "true"
subjects:
- kind: ServiceAccount
  name: task-executor-serviceaccount
  namespace: default
roleRef:
  kind: ClusterRole
  name: task-executor-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: worker-serviceaccount
  labels:
    group: hkube
    app: task-executor
    core: "true"    
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: delete-jobs
  labels:
    group: hkube
    app: task-executor
    core: "true"
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: ["batch", "extensions"]
  resources: ["jobs"]
  verbs: ["delete"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: delete-jobs
  namespace: default
  labels:
    group: hkube
    app: task-executor
    core: "true"
subjects:
- kind: ServiceAccount
  name: worker-serviceaccount
roleRef:
  kind: Role
  name: delete-jobs
  apiGroup: rbac.authorization.k8s.io

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/create-crd-hook.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: etcdclusters.etcd.database.coreos.com
  annotations:
    "helm.sh/hook": crd-install
spec:
  group: etcd.database.coreos.com
  names:
    kind: EtcdCluster
    listKind: EtcdClusterList
    plural: etcdclusters
    shortNames:
    - etcd
    singular: etcdcluster
  scope: Namespaced
  version: v1beta2

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/operator-cluster-role.yaml

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: application-etcd-operator-etcd-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-operator
    heritage: Tiller
    release: application
rules:
- apiGroups:
  - etcd.database.coreos.com
  resources:
  - etcdclusters
  - etcdbackups
  - etcdrestores
  verbs:
  - "*"
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - persistentvolumeclaims
  - events
  verbs:
  - "*"
- apiGroups:
  - apps
  resources:
  - deployments
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/backup-operator-clusterrole-binding.yaml

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: application-etcd-operator-etcd-backup-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-operator
    heritage: Tiller
    release: application
subjects:
- kind: ServiceAccount
  name: application-etcd-operator-etcd-backup-operator
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: application-etcd-operator-etcd-operator

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/operator-clusterrole-binding.yaml

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: application-etcd-operator-etcd-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-operator
    heritage: Tiller
    release: application
subjects:
- kind: ServiceAccount
  name: application-etcd-operator-etcd-operator
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: application-etcd-operator-etcd-operator

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/restore-operator-clusterrole-binding.yaml

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: application-etcd-operator-etcd-restore-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-restore-operator
    heritage: Tiller
    release: application
subjects:
- kind: ServiceAccount
  name: application-etcd-operator-etcd-restore-operator
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: application-etcd-operator-etcd-operator

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-role.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: application-redis-ha
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
rules:
- apiGroups:
    - ""
  resources:
    - pods
  verbs:
    - get
    - list
    - patch
---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: application-redis-ha
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: application-redis-ha
subjects:
- kind: ServiceAccount
  name: application-redis-ha
---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/restore-operator-service.yaml

---
apiVersion: v1
kind: Service
metadata:
  name: etcd-restore-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-restore-operator
    heritage: Tiller
    release: application
spec:
  ports:
  - protocol: TCP
    name: http-etcd-restore-port
    port: 19999
  selector:
    app: etcd-restore-operator
    release: application

---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: jaeger-cassandra
  labels:
    app: jaeger-cassandra
    chart: "cassandra-0.2.4"
    release: "jaeger"
    heritage: "Tiller"
    group: hkube
    thirdparty: "true"
spec:
  clusterIP: None
  type: ClusterIP
  ports:
  - name: intra
    port: 7000
    targetPort: 7000
  - name: tls
    port: 7001
    targetPort: 7001
  - name: jmx
    port: 7199
    targetPort: 7199
  - name: cql
    port: 9042
    targetPort: 9042
  - name: thrift
    port: 9160
    targetPort: 9160
  selector:
    app: jaeger-cassandra
---

apiVersion: v1
kind: Service
metadata:
  name: jaeger-jaeger-agent
  labels:
    app: jaeger
    jaeger-infra: agent-service
    chart: jaeger-0.3.5
    component: agent
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  ports:
  - name: agent-zipkin-thrift
    port: 5775
    protocol: UDP
    targetPort: 5775
  - name: agent-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  - name: agent-binary
    port: 6832
    protocol: UDP
    targetPort: 6832
  - name: agent-sampling
    port: 5778
    protocol: TCP
    targetPort: 5778
  type: ClusterIP
  selector:
    app: jaeger
    component: agent
    release: jaeger
    jaeger-infra: agent-instance
---
# Source: jaeger/templates/collector-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: jaeger-jaeger-collector
  labels:
    app: jaeger
    jaeger-infra: collector-service
    chart: jaeger-0.3.5
    component: collector
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  ports:
  - name: jaeger-collector-tchannel
    port: 14267
    protocol: TCP
    targetPort: tchannel
  - name: jaeger-collector-http
    port: 14268
    protocol: TCP
    targetPort: http
  - name: jaeger-collector-zipkin
    port: 9411
    protocol: TCP
    targetPort: zipkin
  selector:
    app: jaeger
    component: collector
    release: jaeger
    jaeger-infra: collector-pod
  type: ClusterIP
---
# Source: jaeger/templates/query-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: jaeger-jaeger-query
  labels:
    app: jaeger
    jaeger-infra: query-service
    chart: jaeger-0.3.5
    component: query
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  ports:
  - name: jaeger-query
    port: 80
    protocol: TCP
    targetPort: 16686
    nodePort: 30086
  selector:
    app: jaeger
    component: query
    release: jaeger
    jaeger-infra: query-pod
  type: NodePort
---

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-master-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: application-redis-ha-master-svc
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
  annotations:
    {}
    
spec:
  ports:
  - port: 6379
    protocol: TCP
    targetPort: 6379
  selector:
    app: redis-ha
    release: "application"
    redis-node: "true"
    redis-role: "master"
  type: "ClusterIP"

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-sentinel-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-sentinel
  labels:
    name: redis-ha-sentinel-svc
    role: service
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
spec:
  ports:
    - port: 26379
      targetPort: 26379
  selector:
    app: redis-ha
    release: "application"
    redis-role: "sentinel"

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-slave-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: application-redis-ha-slave-svc
  labels:
    role: service
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
  annotations:
    {}
    
spec:
  ports:
  - port: 6379
    protocol: TCP
    targetPort: 6379
  selector:
    app: redis-ha
    release: "application"
    redis-node: "true"
    redis-role: "slave"
  type: "ClusterIP"

---
# Source: hkube/templates/algorithm-operator-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: algorithm-operator
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: algorithm-operator
    chart: algorithm-operator
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  clusterIP: None
  type: "ClusterIP"
  ports:
    - port: 3000
      targetPort: 3000
      protocol: TCP
  selector:
    app: algorithm-operator
    release: application
---
# Source: hkube/templates/algorithm-queue-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: algorithm-queue-svc
  labels:
    app: algorithm-queue-svc
    chart: algorithm-queue-svc
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  type: ClusterIP
  ports:
    - port: 3000
      targetPort: 3000
      protocol: TCP
  selector:
    app: algorithm-queue-svc
    release: application
---
# Source: hkube/templates/api-server-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: api-server
  labels:
    app: api-server
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  type: ClusterIP
  ports:
    - port: 3000
      targetPort: 3000
      protocol: TCP
  selector:
    app: api-server
    release: api-server

---
# Source: hkube/templates/monitor-server-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: monitor-server
  labels:
    app: monitor-server
    group: hkube
    core: "true"
spec:
  selector:
    app: monitor-server
  ports:
    - protocol: TCP
      port: 30010
      targetPort: 30010

---
# Source: hkube/templates/pipeline-driver-queue-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: pipeline-driver-queue
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: pipeline-driver-queue
    group: hkube
    core: "true"
spec:
  selector:
    app: pipeline-driver-queue
  clusterIP: None
  ports:
    - name: metrics
      port: 3000
      targetPort: 3000

---
# Source: hkube/templates/pipeline-driver-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: pipeline-driver
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: pipeline-driver
    group: hkube
    core: "true"
spec:
  selector:
    app: pipeline-driver
  clusterIP: None
  ports:
    - name: metrics
      port: 3000
      targetPort: 3000

---
# Source: hkube/templates/resource-manager-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: resource-manager
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: resource-manager
    group: hkube
    core: "true"
spec:
  selector:
    app: resource-manager
  clusterIP: None
  ports:
    - name: metrics
      port: 3000
      targetPort: 3000

---
# Source: hkube/templates/simulator-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: simulator
  labels:
    app: simulator
    group: hkube
    core: "true"
spec:
  selector:
    app: simulator
  ports:
    - protocol: TCP
      port: 9050
      targetPort: 9050

---
# Source: hkube/templates/task-executor-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: task-executor
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: task-executor
    group: hkube
    core: "true"
spec:
  selector:
    app: task-executor
  clusterIP: None
  ports:
    - name: metrics
      port: 3000
      targetPort: 3000

---
# Source: hkube/templates/trigger-service-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: trigger-service
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: trigger-service
    group: hkube
    core: "true"
spec:
  selector:
    app: trigger-service
  clusterIP: None
  ports:
    - name: metrics
      port: 3000
      targetPort: 3000

---
# Source: hkube/templates/webhook-stub-ui-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: webhook-stub-ui
  labels:
    app: webhook-stub-ui
    group: hkube
    core: "true"
spec:
  selector:
    app: webhook-stub-ui
  ports:
    - name: server
      protocol: TCP
      port: 3002
      targetPort: 3002
---
# Source: hkube/templates/worker-svc.yaml
kind: Service
apiVersion: v1
metadata:
  name: worker
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app: worker
    group: hkube
    core: "true"
spec:
  selector:
    metrics-group: workers
    group: hkube
  clusterIP: None
  ports:
    - name: metrics
      port: 3001
      targetPort: 3001
---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/daemonset.yaml
# Source: jaeger/templates/agent-ds.yaml
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: jaeger-jaeger-agent
  labels:
    app: jaeger
    jaeger-infra: agent-daemonset
    chart: jaeger-0.3.5
    component: agent
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  template:
    metadata:
      labels:
        app: jaeger
        component: agent
        release: jaeger
        jaeger-infra: agent-instance
        group: hkube
        thirdparty: "true"
    spec:
      nodeSelector:
        third-party: "true"
      containers:
      - name: jaeger-jaeger-agent
        image: jaegertracing/jaeger-agent:1.2.0
        imagePullPolicy: IfNotPresent
        env:
        - name: COLLECTOR_HOST_PORT
          valueFrom:
            configMapKeyRef:
              name: jaeger-jaeger
              key: collector.host-port
        ports:
        - containerPort: 5775
          hostPort: 5775
          protocol: UDP
        - containerPort: 6831
          hostPort: 6831
          protocol: UDP
        - containerPort: 6832
          hostPort: 6832
          protocol: UDP
        - containerPort: 5778
          hostPort: 5778
          protocol: TCP
        resources:
          {}
---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/tests/test-redis-master-service.yaml
apiVersion: v1
kind: Pod
metadata:
  name: application-redis-ha-master-service-test
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
  - name: "application-master-service-test"
    image: quay.io/smile/redis:4.0.6r2
    env:
      - name: REDIS_CHART_PREFIX
        value: application-redis-ha-
    command:
      - sh
      - -c
      - redis-cli -h ${REDIS_CHART_PREFIX}master-svc info server
  restartPolicy: Never

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/tests/test-redis-sentinel-service.yaml
apiVersion: v1
kind: Pod
metadata:
  name: application-redis-ha-sentinel-service-test
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
  - name: "application-sentinel-service-test"
    image: quay.io/smile/redis:4.0.6r2
    env:
      - name: REDIS_CHART_PREFIX
        value: application-redis-ha-
    command:
      - sh
      - -c
      - redis-cli -h ${REDIS_CHART_PREFIX}sentinel -p 26379 info server
  restartPolicy: Never

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/tests/test-redis-slave-service.yaml
apiVersion: v1
kind: Pod
metadata:
  name: application-redis-ha-slave-service-test
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
  - name: "application-slave-service-test"
    image: quay.io/smile/redis:4.0.6r2
    env:
      - name: REDIS_CHART_PREFIX
        value: application-redis-ha-
    command:
      - sh
      - -c
      - redis-cli -h ${REDIS_CHART_PREFIX}slave-svc info server
  restartPolicy: Never

---
# Source: hkube/templates/busybox-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  labels:
    app: busybox
    group: hkube
    thirdparty: "true"
spec:
  containers:
  - image: "busybox:latest"
    command:
      - sleep
      - "3600"
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Always
---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/backup-operator-deployment.yaml

---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: application-etcd-operator-etcd-backup-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-backup-operator
    heritage: Tiller
    release: application
spec:
  replicas: 1
  template:
    metadata:
      name: application-etcd-operator-etcd-backup-operator
      labels:
        app: application-etcd-operator-etcd-backup-operator
        release: application
    spec:
      serviceAccountName: application-etcd-operator-etcd-backup-operator
      containers:
      - name: etcd-backup-operator
        image: "quay.io/coreos/etcd-operator:v0.9.2"
        imagePullPolicy: Always
        command:
        - etcd-backup-operator
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 128Mi

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/operator-deployment.yaml

---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: application-etcd-operator-etcd-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-operator
    heritage: Tiller
    release: application
spec:
  replicas: 1
  template:
    metadata:
      name: application-etcd-operator-etcd-operator
      labels:
        app: application-etcd-operator-etcd-operator
        release: application
    spec:
      serviceAccountName: application-etcd-operator-etcd-operator
      containers:
      - name: application-etcd-operator-etcd-operator
        image: "quay.io/coreos/etcd-operator:v0.9.2"
        imagePullPolicy: Always
        command:
        - etcd-operator
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 128Mi

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/restore-operator-deployment.yaml

---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: application-etcd-operator-etcd-restore-operator
  labels:
    chart: "etcd-operator-0.9.2"
    app: etcd-restore-operator
    heritage: Tiller
    release: application
spec:
  replicas: 1
  template:
    metadata:
      name: application-etcd-operator-etcd-restore-operator
      labels:
        app: etcd-restore-operator
        release: application
    spec:
      serviceAccountName: application-etcd-operator-etcd-restore-operator
      containers:
      - name: etcd-restore-operator
        image: "quay.io/coreos/etcd-operator:v0.9.2"
        imagePullPolicy: Always
        ports:
        - containerPort: 19999
        command:
        - etcd-restore-operator
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SERVICE_ADDR
          value: "etcd-restore-operator:19999"
        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 100m
            memory: 128Mi

---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/collector-deploy.yaml
# Source: jaeger/templates/collector-deploy.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: jaeger-jaeger-collector
  labels:
    app: jaeger
    jaeger-infra: collector-deployment
    chart: jaeger-0.3.5
    component: collector
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: jaeger
        component: collector
        release: jaeger
        jaeger-infra: collector-pod
        group: hkube
        thirdparty: "true"
    spec:
      nodeSelector:
        third-party: "true"
      containers:
      - name: jaeger-jaeger-collector
        image: jaegertracing/jaeger-collector:1.2.0
        imagePullPolicy: IfNotPresent
        env:
          - name: SPAN_STORAGE_TYPE
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: span-storage.type
          - name: CASSANDRA_SERVERS
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.servers
          - name: CASSANDRA_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.port
          - name: CASSANDRA_KEYSPACE
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.keyspace
          - name: COLLECTOR_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: collector.port
          - name: COLLECTOR_HTTP_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: collector.http-port
          - name: COLLECTOR_ZIPKIN_HTTP_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: collector.zipkin.http-port
        ports:
        - containerPort: 14267
          name: tchannel
          protocol: TCP
        - containerPort: 14268
          name: http
          protocol: TCP
        - containerPort: 9411
          name: zipkin
          protocol: TCP
        resources:
          {}
          
      dnsPolicy: ClusterFirst
      restartPolicy: Always
---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/deployment.yaml
# apiVersion: apps/v1beta2
# kind: Deployment
# metadata:
#   name: application-jaeger
#   labels:
#     app: jaeger
#     chart: jaeger-0.1.2
#     release: application
#     heritage: Tiller
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: jaeger
#       release: application
#       group: hkube
#       thirdparty: "true"
#   template:
#     metadata:
#       labels:
#         app: jaeger
#         release: application
#     spec:
#       containers:
#         - name: jaeger
#           image: "nginx:stable"
#           imagePullPolicy: IfNotPresent
#           ports:
#             - name: http
#               containerPort: 80
#               protocol: TCP
#           resources:
#             {}
            
#
#
#

---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/query-deploy.yaml
# Source: jaeger/templates/query-deploy.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: jaeger-jaeger-query
  labels:
    app: jaeger
    jaeger-infra: query-deployment
    chart: jaeger-0.3.5
    component: query
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: jaeger
        component: query
        release: jaeger
        jaeger-infra: query-pod
        group: hkube
        thirdparty: "true"
    spec:
      nodeSelector:
        third-party: "true"
      containers:
      - name: jaeger-jaeger-query
        image: jaegertracing/jaeger-query:1.4.1
        imagePullPolicy: IfNotPresent
        env:
          - name: QUERY_BASE_PATH
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: query.base-path
          - name: SPAN_STORAGE_TYPE
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: span-storage.type
          - name: CASSANDRA_SERVERS
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.servers
          - name: CASSANDRA_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.port
          - name: CASSANDRA_KEYSPACE
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: cassandra.keyspace
          - name: QUERY_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: query.port
          - name: QUERY_HEALTH_CHECK_HTTP_PORT
            valueFrom:
              configMapKeyRef:
                name: jaeger-jaeger
                key: query.health-check-http-port
        ports:
        - containerPort: 16686
          protocol: TCP
        resources:
          {}
          
        readinessProbe:
          httpGet:
            path: /
            port: 16687
      dnsPolicy: ClusterFirst
      restartPolicy: Always
---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-sentinel-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: application-redis-ha-sentinel
  labels:
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: redis-ha
        release: application
        component: sentinel
        name: application-redis-ha-sentinel
    spec:
      serviceAccountName: application-redis-ha
      containers:
      - name: sentinel
        image: quay.io/smile/redis:4.0.6r2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
          
        env:
          - name: SENTINEL
            value: "true"
          - name: REDIS_CHART_PREFIX
            value: application-redis-ha-
        ports:
          - containerPort: 26379

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-server-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  # Pay attention to the redis-role label at runtime. The self-determination logic in the image sets this value accordingly.
  name: application-redis-ha-server
  labels:
    name: application-redis-ha-server
    redis-node: "true"
    app: redis-ha
    heritage: "Tiller"
    release: "application"
    chart: redis-ha-2.1.3
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: redis-ha
        release: application
        component: server
        name: application-redis-ha-server
        redis-node: "true"
    spec:
      serviceAccountName: application-redis-ha
      containers:
      - name: redis
        image: quay.io/smile/redis:4.0.6r2
        resources:
          limits:
            memory: 700Mi
          requests:
            cpu: 100m
            memory: 200Mi
          
        env:
          - name: REDIS_SENTINEL_SERVICE_HOST
            value: "redis-sentinel"
          - name: REDIS_CHART_PREFIX
            value: application-redis-ha-
        ports:
          - containerPort: 6379
        volumeMounts:
          - mountPath: /redis-master-data
            name: data
      volumes:
      - name: data


---
# Source: hkube/charts/thirdparty/templates/etcd-ui.yml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: etcd-ui
  labels:
    app: etcd-ui
    group: hkube
    third-party: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: etcd-ui
  template:
    metadata:
      labels:
        app: etcd-ui
        group: hkube
    spec:
      containers:
        - name: etcd-ui
          image: "hkube/etcd-ui:v1.0.3"
          env: 
            - name: HOST
              value: "0.0.0.0"
          ports:
            - containerPort: 8080
---
kind: Service
apiVersion: v1
metadata:
  name: etcd-ui
  labels:
    app: etcd-ui
    release: application
    heritage: Tiller
    third-party: "true"
spec:
  selector:
    app: etcd-ui
  ports:
    - name: server
      protocol: TCP
      port: 8080
      targetPort: 8080

---apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: etcd-ui
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  labels:
    app: etcd-ui
    release: application
    heritage: Tiller
    core: "true"
spec:
  rules:
    - http:
        paths:
        - path: /hkube/etcd-ui
          backend:
            serviceName: etcd-ui
            servicePort: 8080




---
# Source: hkube/templates/algorithm-operator-deployment.yaml
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: algorithm-operator
  labels:
    app: algorithm-operator
    release: algorithm-operator
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: algorithm-operator
  template:
    metadata:
      labels:
        app: algorithm-operator
        release: algorithm-operator
        group: hkube
    spec:
      serviceAccountName: algorithm-operator-serviceaccount
      containers:
        - name: algorithm-operator
          image: "hkube/algorithm-operator:v1.1.10"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: algorithm-operator-configmap
                  key: NODE_ENV
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: algorithm-operator-configmap
                  key: METRICS_PORT
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          resources:
            {}
            

---
# Source: hkube/templates/api-server-deployment.yaml
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: api-server
  labels:
    app: api-server
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api-server
      release: api-server
  template:
    metadata:
      labels:
        app: api-server
        release: api-server
        group: hkube
    spec:
      containers:
        - name: api-server
          image: "hkube/api-server:v1.1.73"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 3000
              protocol: TCP
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: api-server-configmap
                  key: NODE_ENV
            - name: BASE_URL_PATH
              valueFrom:
                configMapKeyRef:
                  name: api-server-configmap
                  key: BASE_URL_PATH
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-secret
                  key: awsKey
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-secret
                  key: awsSecret
            - name: S3_ENDPOINT_URL
              valueFrom:
                secretKeyRef:
                  name: s3-secret
                  key: awsEndpointUrl
            - name: DEFAULT_STORAGE
              valueFrom:
                configMapKeyRef:
                  name: api-server-configmap
                  key: DEFAULT_STORAGE
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          resources:
            {}
            

---
# Source: hkube/templates/monitor-server-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: monitor-server
  labels:
    app: monitor-server
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: monitor-server
  template:
    metadata:
      labels:
        app: monitor-server
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      containers:
        - name: monitor-server
          image: "hkube/monitor-server:v1.1.18"
          ports:
            - containerPort: 30010
          volumeMounts:
            - name: versions-config
              mountPath: /versions
      volumes:
        - name: versions-config
          configMap:
            name: hkube-versions
---
# Source: hkube/templates/pipeline-driver-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: pipeline-driver
  labels:
    app: pipeline-driver
    scale-group: pipeline-driver
    group: hkube
    core: "true"
spec:
  replicas: 20
  selector:
    matchLabels:
      app: pipeline-driver
  template:
    metadata:
      labels:
        app: pipeline-driver
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      containers:
        - name: pipeline-driver
          image: "hkube/pipeline-driver:v1.1.28"
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: pipeline-driver-configmap
                  key: NODE_ENV
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: pipeline-driver-configmap
                  key: METRICS_PORT
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-secret
                  key: awsKey
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-secret
                  key: awsSecret
            - name: S3_ENDPOINT_URL
              valueFrom: 
                secretKeyRef:
                  name: s3-secret
                  key: awsEndpointUrl
            - name: DEFAULT_STORAGE
              value: "s3"
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP

---
# Source: hkube/templates/pipeline-driver-queue-deployment.yaml
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: pipeline-driver-queue
  labels:
    app: pipeline-driver-queue
    group: hkube
    core: "true"
    metrics-group: pipeline-driver-queue
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pipeline-driver-queue
  template:
    metadata:
      labels:
        app: pipeline-driver-queue
        group: hkube
    spec:
      containers:
        - name: pipeline-driver-queue
          image: "hkube/pipeline-driver-queue:v1.1.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: pipeline-driver-queue-configmap
                  key: NODE_ENV
            - name: HKUBE_LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: pipeline-driver-queue-configmap
                  key: KUBE_LOG_LEVEL
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: pipeline-driver-queue-configmap
                  key: METRICS_PORT
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          resources:
            {}
            
---
# Source: hkube/templates/resource-manager-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: resource-manager
  labels:
    app: resource-manager
    scale-group: resource-manager
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: resource-manager
  template:
    metadata:
      labels:
        app: resource-manager
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      serviceAccountName: resource-manager-serviceaccount
      containers:
        - name: resource-manager
          image: "hkube/resource-manager:v1.1.32"
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: NODE_ENV
            - name: HKUBE_LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: HKUBE_LOG_LEVEL
            - name: INTERVAL
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: INTERVAL
            - name: ALGORITHMS_THRESHOLD_CPU
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: ALGORITHMS_THRESHOLD_CPU
            - name: ALGORITHMS_THRESHOLD_MEM
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: ALGORITHMS_THRESHOLD_MEM
            - name: DRIVERS_THRESHOLD_CPU
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: DRIVERS_THRESHOLD_CPU
            - name: DRIVERS_THRESHOLD_MEM
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: DRIVERS_THRESHOLD_MEM
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: METRICS_PORT
            - name: PROMETHEUS_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: resource-manager-configmap
                  key: PROMETHEUS_ENDPOINT
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP

---
# Source: hkube/templates/simulator-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: simulator
  labels:
    app: simulator
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: simulator
  template:
    metadata:
      labels:
        app: simulator
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      containers:
        - name: simulator
          image: "hkube/simulator:v1.1.13"
          ports:
            - containerPort: 9050
          env:
            - name: MONITOR_BACKEND_PATH
              valueFrom:
                configMapKeyRef:
                  name: simulator-configmap
                  key: MONITOR_BACKEND_PATH

---
# Source: hkube/templates/task-executor-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: task-executor
  labels:
    app: task-executor
    scale-group: task-executor
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: task-executor
  template:
    metadata:
      labels:
        app: task-executor
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      serviceAccountName: task-executor-serviceaccount
      containers:
        - name: task-executor
          image: "hkube/task-executor:v1.1.44"
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: task-executor-configmap
                  key: NODE_ENV
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: task-executor-configmap
                  key: METRICS_PORT
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP

---
# Source: hkube/templates/trigger-service-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: trigger-service
  labels:
    app: trigger-service
    scale-group: trigger-service
    group: hkube
    core: "true"
    metrics-group: trigger-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trigger-service
  template:
    metadata:
      labels:
        app: trigger-service
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      containers:
        - name: trigger-service
          image: 'hkube/trigger-service:latest'
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: trigger-service-configmap
                  key: NODE_ENV
            - name: METRICS_PORT
              valueFrom:
                configMapKeyRef:
                  name: trigger-service-configmap
                  key: METRICS_PORT
            - name: JAEGER_AGENT_SERVICE_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
---
# Source: hkube/templates/webhook-stub-ui-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: webhook-stub-ui
  labels:
    app: webhook-stub-ui
    group: hkube
    core: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webhook-stub-ui
  template:
    metadata:
      labels:
        app: webhook-stub-ui
        group: hkube
    spec:
      nodeSelector:
        core: "true"
      containers:
        - name: webhook-stub-ui
          image: "hkube/webhook-stub-ui:v1.1.2"
          ports:
            - containerPort: 3002
          env:
          - name: PUBLIC_URL
            valueFrom:
                configMapKeyRef:
                  name: webhook-stub-ui-configmap
                  key: PUBLIC_URL
---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/cassandra.yaml
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: jaeger-cassandra
  labels:
    app: jaeger-cassandra
    chart: "cassandra-0.2.4"
    release: "jaeger"
    heritage: "Tiller"
    group: hkube
    thirdparty: "true"
spec:
  serviceName: jaeger-cassandra
  replicas: 3
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: OnDelete
  template:
    metadata:
      labels:
        app: jaeger-cassandra
        group: hkube
        thirdparty: "true"
    spec:
      containers:
      - name: jaeger-cassandra
        image: "cassandra:3.11"
        imagePullPolicy: "IfNotPresent"
        resources:
          limits:
            cpu: 2
            memory: 4Gi
          requests:
            cpu: 2
            memory: 4Gi
          
        env:
        - name: CASSANDRA_SEEDS
          value: "jaeger-cassandra-0.jaeger-cassandra.default.svc.dev "
        - name: MAX_HEAP_SIZE
          value: "2048M"
        - name: HEAP_NEWSIZE
          value: "512M"
        - name: CASSANDRA_ENDPOINT_SNITCH
          value: "GossipingPropertyFileSnitch"
        - name: CASSANDRA_CLUSTER_NAME
          value: "jaeger"
        - name: CASSANDRA_DC
          value: "dc1"
        - name: CASSANDRA_RACK
          value: "rack1"
        - name: CASSANDRA_START_RPC
          value: "false"
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        livenessProbe:
          exec:
            command: [ "/bin/sh", "-c", "nodetool status" ]
          initialDelaySeconds: 90
          periodSeconds: 30
        readinessProbe:
          exec:
            command: [ "/bin/sh", "-c", "nodetool status | grep -E \"^UN\\s+${POD_IP}\"" ]
          initialDelaySeconds: 90
          periodSeconds: 30
        ports:
        - name: intra
          containerPort: 7000
        - name: tls
          containerPort: 7001
        - name: jmx
          containerPort: 7199
        - name: cql
          containerPort: 9042
        - name: thrift
          containerPort: 9160
        volumeMounts:
        - name: data
          mountPath: /var/lib/cassandra
      volumes:
      - name: data
        emptyDir: {}
---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/cassandra-schema-job.yaml

---
# Source: jaeger/templates/cassandra-schema-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: jaeger-jaeger-cassandra-schema
  labels:
    app: jaeger
    jaeger-infra: cassandra-schema-job
    chart: jaeger-0.3.5
    component: cassandra-schema
    heritage: Tiller
    release: jaeger
    group: hkube
    thirdparty: "true"
spec:
  activeDeadlineSeconds: 120
  template:
    metadata:
      name: jaeger-jaeger-cassandra-schema
    spec:
      containers:
      - name: jaeger-jaeger-cassandra-schema
        image: jaegertracing/jaeger-cassandra-schema:1.2.0
        imagePullPolicy: IfNotPresent
        env:
        - name: CQLSH_HOST
          valueFrom:
            configMapKeyRef:
              name: jaeger-jaeger
              key: cassandra.servers
        - name: MODE
          valueFrom:
            configMapKeyRef:
              name: jaeger-jaeger
              key: cassandra.schema.mode
        - name: DATACENTER
          valueFrom:
            configMapKeyRef:
              name: jaeger-jaeger
              key: cassandra.datacenter.name
        - name: CASSANDRA_PORT
          valueFrom:
            configMapKeyRef:
              name: jaeger-jaeger
              key: cassandra.port
        resources:
          {}
          
      restartPolicy: OnFailure
---
# Source: hkube/templates/post-delete.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "post-del-dep-and-jobs"
  labels:
    chart: "hkube-0.1.2"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "resource-policy": delete-on-completion
    "helm.sh/hook": post-delete,pre-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    metadata:
      name: "post-del-dep-and-jobs"
      labels:
        heritage: "Tiller"
        release: "application"
        chart: "hkube-0.1.2"
    spec:
      serviceAccountName: default
      restartPolicy: Never
      containers:
      - name: post-del-dep-and-jobs
        image: "hkube/del-dep-and-jobs:v1.0.8"
        command:
          - /bin/sh
          - -c
          - |
            /usr/local/bin/kubectl delete deploy -l metrics-group=algorithm-queue
            /usr/local/bin/kubectl  delete job -l delete-group=delete-dep-and-jobs
            /usr/local/bin/kubectl  delete crd etcdclusters.etcd.database.coreos.com
            echo Done
---
# Source: hkube/templates/job-cleaner-deployment.yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: clean-old-jobs
  labels:
    group: hkube
    delete-group: delete-dep-and-jobs
    core: "true"
spec:
  schedule: "*/10 * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          name: clean-old-jobs
          labels:
            group: hkube
            delete-group: delete-dep-and-jobs
        spec:
          serviceAccountName: clean-old-jobs
          containers:
          - name: clean-old-jobs
            image: "hkube/clean-old-jobs:v1.1.2"
            env:
            - name: "MAX_COMPLETED_JOB_AGE_HOURS"
              valueFrom:
                configMapKeyRef:
                  name: job-cleaner-configmap
                  key: MAX_COMPLETED_JOB_AGE_HOURS
          restartPolicy: Never

---
# Source: hkube/charts/thirdparty/charts/jaeger/templates/ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: jaeger
  labels:
    app: jaeger
    chart: jaeger-0.1.2
    release: application
    heritage: Tiller
    group: hkube
    thirdparty: "true"
spec:
  rules:
    - http:
         paths:
         - path: /jaeger
           backend:
             serviceName: jaeger-jaeger-query
             servicePort: 80

---
# Source: hkube/templates/api-server-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: api-server
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  labels:
    app: api-server
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  rules:
    - http:
        paths:
        - path: /hkube/api-server
          backend:
            serviceName: api-server
            servicePort: 3000
---
# Source: hkube/templates/monitor-server-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: monitor-server
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  labels:
    app: monitor-server
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  rules:
    - http:
        paths:
        - path: /hkube/monitor-server
          backend:
            serviceName: monitor-server
            servicePort: 30010



---
# Source: hkube/templates/simulator-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: simulator
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  labels:
    app: simulator
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  rules:
    - http:
        paths:
        - path: /hkube/simulator
          backend:
            serviceName: simulator
            servicePort: 9050

---
# Source: hkube/templates/webhook-stub-ui-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: webhook-stub-ui
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  labels:
    app: webhook-stub-ui
    release: application
    heritage: Tiller
    group: hkube
    core: "true"
spec:
  rules:
    - http:
        paths:
        - path: /hkube/webhook-stub-ui
          backend:
            serviceName: webhook-stub-ui
            servicePort: 3002
---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/etcd-cluster.yaml
apiVersion: "etcd.database.coreos.com/v1beta2"
kind: "EtcdCluster"
metadata:
  name: "etcd"
  labels:
    group: hkube
    app: etcd
    thirdparty: "true"
spec:
  size: 3
  version: "3.3.1"
  repository: "gcr.io/etcd-development/etcd"
  pod:
    busyboxImage: "busybox:1.28.0-glibc"
    nodeSelector:
      third-party: "true"
    etcdEnv:
    - name: ETCD_HEARTBEAT_INTERVAL
      value: "1000"
    - name: ETCD_ELECTION_TIMEOUT
      value: "5000"
    - name: ETCD_AUTO_COMPACTION_RETENTION
      value: "5m"
    - name: ETCD_AUTO_COMPACTION_MODE
      value: "periodic"
    - name: ETCD_QUOTA_BACKEND_BYTES
    # 8GB
      value: "8589934592"
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "2379"

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/backup-etcd-crd.yaml

---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/etcd-cluster-crd.yaml



---
# Source: hkube/charts/thirdparty/charts/etcd-operator/templates/restore-etcd-crd.yaml

---
# Source: hkube/charts/thirdparty/charts/redis-ha/templates/redis-auth-secret.yaml

---
# Source: hkube/charts/thirdparty/templates/deployment.yaml

---
# Source: hkube/templates/algorithm-operator-ingress.yaml

---
# Source: hkube/templates/pipeline-driver-queue-ingress.yaml


